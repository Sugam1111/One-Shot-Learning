{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Shot Learning using Siamese networks on Omniglot Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-22T16:45:21.507Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sys, os, time\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy.random as rng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8vv_dgjN4kzb"
   },
   "source": [
    "## Loading Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T16:47:42.148064Z",
     "start_time": "2020-06-22T16:47:42.144075Z"
    }
   },
   "outputs": [],
   "source": [
    "data_folder = './images_background/'\n",
    "save_path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T16:48:30.358088Z",
     "start_time": "2020-06-22T16:48:11.611207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alphabet_of_the_Magi': [0, 19],\n",
       " 'Anglo-Saxon_Futhorc': [20, 48],\n",
       " 'Arcadian': [49, 74],\n",
       " 'Armenian': [75, 115],\n",
       " 'Asomtavruli_(Georgian)': [116, 155],\n",
       " 'Balinese': [156, 179],\n",
       " 'Bengali': [180, 225],\n",
       " 'Blackfoot_(Canadian_Aboriginal_Syllabics)': [226, 239],\n",
       " 'Braille': [240, 265],\n",
       " 'Burmese_(Myanmar)': [266, 299],\n",
       " 'Cyrillic': [300, 332],\n",
       " 'Early_Aramaic': [333, 354],\n",
       " 'Futurama': [355, 380],\n",
       " 'Grantha': [381, 423],\n",
       " 'Greek': [424, 447],\n",
       " 'Gujarati': [448, 495],\n",
       " 'Hebrew': [496, 517],\n",
       " 'Inuktitut_(Canadian_Aboriginal_Syllabics)': [518, 533],\n",
       " 'Japanese_(hiragana)': [534, 585],\n",
       " 'Japanese_(katakana)': [586, 632],\n",
       " 'Korean': [633, 672],\n",
       " 'Latin': [673, 698],\n",
       " 'Malay_(Jawi_-_Arabic)': [699, 738],\n",
       " 'Mkhedruli_(Georgian)': [739, 779],\n",
       " 'N_Ko': [780, 812],\n",
       " 'Ojibwe_(Canadian_Aboriginal_Syllabics)': [813, 826],\n",
       " 'Sanskrit': [827, 868],\n",
       " 'Syriac_(Estrangelo)': [869, 891],\n",
       " 'Tagalog': [892, 908],\n",
       " 'Tifinagh': [909, 963]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "lang_dict = {}\n",
    "character_count = 0\n",
    "\n",
    "for alphabet in os.listdir(data_folder):\n",
    "    \n",
    "    # print(\"loading alphabet: \" + alphabet)\n",
    "    lang_dict[alphabet] = [character_count, None]\n",
    "    alphabet_path = os.path.join(data_folder, alphabet)\n",
    "    \n",
    "    for letter in os.listdir(alphabet_path):\n",
    "        character_images = []\n",
    "        character_path = os.path.join(alphabet_path, letter)\n",
    "        # read all the images for the current character\n",
    "        for filename in os.listdir(character_path):\n",
    "            image_path = os.path.join(character_path, filename)\n",
    "            image = plt.imread(image_path)\n",
    "            character_images.append(image)\n",
    "            y.append(character_count)\n",
    "        try:\n",
    "            X.append(np.stack(character_images))\n",
    "        # edge case - last one\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            print(\"error - category_images:\", character_images)\n",
    "        character_count += 1\n",
    "    lang_dict[alphabet][1] = character_count - 1\n",
    "    \n",
    "y = np.vstack(y)\n",
    "X = np.stack(X)\n",
    "lang_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tXM41p5O4lM-"
   },
   "source": [
    "### Train Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T16:48:36.704716Z",
     "start_time": "2020-06-22T16:48:36.697734Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "6UhiZCOS4lOe"
   },
   "outputs": [],
   "source": [
    "split = 673\n",
    "X_train, X_val = X[:split], X[split:]\n",
    "\n",
    "train_classes = {}\n",
    "for alphabet in list(lang_dict.keys())[:21]:\n",
    "    train_classes[alphabet] = lang_dict[alphabet]\n",
    "    \n",
    "val_classes = {}\n",
    "for alphabet in list(lang_dict.keys())[21:]:\n",
    "    val_classes[alphabet] = lang_dict[alphabet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T16:48:40.406829Z",
     "start_time": "2020-06-22T16:48:40.400835Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "SCzEp7Vf4muy",
    "outputId": "2aba78f7-87f9-4cf4-8c3a-9906f1fa5c17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((673, 20, 105, 105), (291, 20, 105, 105))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T16:48:59.561827Z",
     "start_time": "2020-06-22T16:48:59.556812Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Yg7RFxr_4lVv"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(shape, name=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer weights with mean as 0.0 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T16:49:00.369645Z",
     "start_time": "2020-06-22T16:49:00.364652Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "AmCZYl9i4lzB"
   },
   "outputs": [],
   "source": [
    "def initialize_bias(shape, name=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer bias with mean as 0.5 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T16:49:01.574676Z",
     "start_time": "2020-06-22T16:49:01.564696Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ohbHJPHL4lzK"
   },
   "outputs": [],
   "source": [
    "def get_siamese_model(input_shape):\n",
    "    \"\"\"\n",
    "        Model architecture based on the one provided in: http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the tensors for the two input images\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "    \n",
    "    # Convolutional Neural Network\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (10,10), activation='relu', input_shape=input_shape,\n",
    "                   kernel_initializer=initialize_weights, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (7,7), activation='relu',\n",
    "                     kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(256, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
    "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='sigmoid',\n",
    "                   kernel_regularizer=l2(1e-3),\n",
    "                   kernel_initializer=initialize_weights,bias_initializer=initialize_bias))\n",
    "    \n",
    "    # Generate the encodings (feature vectors) for the two images\n",
    "    encoded_l = model(left_input)\n",
    "    encoded_r = model(right_input)\n",
    "    \n",
    "    # Add a customized layer to compute the absolute difference between the encodings\n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "    \n",
    "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "    prediction = Dense(1,activation='sigmoid',bias_initializer=initialize_bias)(L1_distance)\n",
    "    \n",
    "    # Connect the inputs with the outputs\n",
    "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    \n",
    "    # return the model\n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T16:49:02.365660Z",
     "start_time": "2020-06-22T16:49:02.356712Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "lRbqb59l4mu-"
   },
   "outputs": [],
   "source": [
    "def get_batch(batch_size,s=\"train\"):\n",
    "    \"\"\"Create batch of n pairs, half same class, half different class\"\"\"\n",
    "    if s == 'train':\n",
    "        X = X_train\n",
    "        categories = train_classes\n",
    "    else:\n",
    "        X = X_val\n",
    "        categories = val_classes\n",
    "    n_classes, n_examples, w, h = X.shape\n",
    "\n",
    "    # randomly sample several classes to use in the batch\n",
    "    categories = rng.choice(n_classes,size=(batch_size,),replace=False)\n",
    "    \n",
    "    # initialize 2 empty arrays for the input image batch\n",
    "    pairs = [np.zeros((batch_size, h, w, 1)) for i in range(2)]\n",
    "    \n",
    "    # initialize vector for the targets\n",
    "    targets = np.zeros((batch_size,))\n",
    "    \n",
    "    # make one half of it '1's, so 2nd half of batch has same class\n",
    "    targets[batch_size//2:] = 1\n",
    "    for i in range(batch_size):\n",
    "        category = categories[i]\n",
    "        idx_1 = rng.randint(0, n_examples)\n",
    "        pairs[0][i,:,:,:] = X[category, idx_1].reshape(w, h, 1)\n",
    "        idx_2 = rng.randint(0, n_examples)\n",
    "        \n",
    "        # pick images of same class for 1st half, different for 2nd\n",
    "        if i >= batch_size // 2:\n",
    "            category_2 = category  \n",
    "        else: \n",
    "            # add a random number to the category modulo n classes to ensure 2nd image has a different category\n",
    "            category_2 = (category + rng.randint(1,n_classes)) % n_classes\n",
    "        \n",
    "        pairs[1][i,:,:,:] = X[category_2,idx_2].reshape(w, h,1)\n",
    "    \n",
    "    return pairs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T16:49:03.320136Z",
     "start_time": "2020-06-22T16:49:03.315123Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "z2LVjUYO4mvC"
   },
   "outputs": [],
   "source": [
    "def generate(batch_size, s=\"train\"):\n",
    "    \"\"\"a generator for batches, so model.fit_generator can be used. \"\"\"\n",
    "    while True:\n",
    "        pairs, targets = get_batch(batch_size,s)\n",
    "        yield (pairs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T16:49:04.077086Z",
     "start_time": "2020-06-22T16:49:04.067113Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "IP2nQPIV4mvF"
   },
   "outputs": [],
   "source": [
    "def make_oneshot_task(N, s=\"val\", language=None):\n",
    "    \"\"\"Create pairs of test image, support set for testing N way one-shot learning. \"\"\"\n",
    "    if s == 'train':\n",
    "        X = X_train\n",
    "        categories = train_classes\n",
    "    else:\n",
    "        X = X_val\n",
    "        categories = val_classes\n",
    "    n_classes, n_examples, w, h = X.shape\n",
    "    \n",
    "    indices = rng.randint(0, n_examples,size=(N,))\n",
    "    if language is not None: # if language is specified, select characters for that language\n",
    "        low, high = categories[language]\n",
    "        if N > high - low:\n",
    "            raise ValueError(\"This language ({}) has less than {} letters\".format(language, N))\n",
    "        categories = rng.choice(range(low,high),size=(N,),replace=False)\n",
    "\n",
    "    else: # if no language specified just pick a bunch of random letters\n",
    "        categories = rng.choice(range(n_classes),size=(N,),replace=False)            \n",
    "    true_category = categories[0]\n",
    "    ex1, ex2 = rng.choice(n_examples,replace=False,size=(2,))\n",
    "    test_image = np.asarray([X[true_category,ex1,:,:]]*N).reshape(N, w, h,1)\n",
    "    support_set = X[categories,indices,:,:]\n",
    "    support_set[0,:,:] = X[true_category,ex2]\n",
    "    support_set = support_set.reshape(N, w, h,1)\n",
    "    targets = np.zeros((N,))\n",
    "    targets[0] = 1\n",
    "    targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
    "    pairs = [test_image,support_set]\n",
    "\n",
    "    return pairs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T16:49:05.744655Z",
     "start_time": "2020-06-22T16:49:05.738644Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "CXXh4lS34nAP"
   },
   "outputs": [],
   "source": [
    "def test_oneshot(model, N, k, s = \"val\", verbose = 0):\n",
    "    \"\"\"Test average N way oneshot learning accuracy of a siamese neural net over k one-shot tasks\"\"\"\n",
    "    n_correct = 0\n",
    "    if verbose:\n",
    "        print(\"Evaluating model on {} random {} way one-shot learning tasks ... \\n\".format(k,N))\n",
    "    for i in range(k):\n",
    "        inputs, targets = make_oneshot_task(N,s)\n",
    "        probs = model.predict(inputs)\n",
    "        if np.argmax(probs) == np.argmax(targets):\n",
    "            n_correct+=1\n",
    "    percent_correct = (100.0 * n_correct / k)\n",
    "    if verbose:\n",
    "        print(\"Got an average of {}% {} way one-shot learning accuracy \\n\".format(percent_correct,N))\n",
    "    return percent_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "colab_type": "code",
    "id": "-aVENj4_4lzW",
    "outputId": "c925f567-c3b4-4728-fa33-956d61ae2866",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 105, 105, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 105, 105, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 4096)         38947648    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 4096)         0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            4097        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 38,951,745\n",
      "Trainable params: 38,951,745\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_siamese_model((105, 105, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R3XYTTnj4mMW"
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(lr = 0.00006)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_5jkANdt4nAU"
   },
   "source": [
    "## Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V7_uVKAC4nAZ"
   },
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "evaluate_every = 200 # interval for evaluating on one-shot tasks\n",
    "batch_size = 32\n",
    "n_iter = 20000 # No. of training iterations\n",
    "N_way = 10 # how many classes for testing one-shot tasks\n",
    "n_val = 100 # how many one-shot tasks to validate on\n",
    "best = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k6aO4WkR4nAe"
   },
   "outputs": [],
   "source": [
    "model_path = './model_evaluation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 15476
    },
    "colab_type": "code",
    "id": "kKmogbYv4nAj",
    "outputId": "a8f63082-e8b7-48f0-8069-6e5332bb39ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training process!\n",
      "-------------------------------------\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 200 iterations: 0.7782549897829691 mins\n",
      "Train Loss: 2.554734230041504\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 49.0% 10 way one-shot learning accuracy \n",
      "\n",
      "Current best: 49.0, previous best: -1\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 400 iterations: 1.4364153504371644 mins\n",
      "Train Loss: 1.8151233196258545\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 59.0% 10 way one-shot learning accuracy \n",
      "\n",
      "Current best: 59.0, previous best: 49.0\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 600 iterations: 2.087701916694641 mins\n",
      "Train Loss: 1.45762300491333\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 65.0% 10 way one-shot learning accuracy \n",
      "\n",
      "Current best: 65.0, previous best: 59.0\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 800 iterations: 2.7410284280776978 mins\n",
      "Train Loss: 1.1724724769592285\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 64.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1000 iterations: 3.393799082438151 mins\n",
      "Train Loss: 1.0837416648864746\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 67.0% 10 way one-shot learning accuracy \n",
      "\n",
      "Current best: 67.0, previous best: 65.0\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1200 iterations: 4.047622728347778 mins\n",
      "Train Loss: 0.8828351497650146\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 61.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1400 iterations: 4.699974556763967 mins\n",
      "Train Loss: 0.9567474722862244\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 78.0% 10 way one-shot learning accuracy \n",
      "\n",
      "Current best: 78.0, previous best: 67.0\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1600 iterations: 5.352337503433228 mins\n",
      "Train Loss: 0.7869923114776611\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 74.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 1800 iterations: 6.005975957711538 mins\n",
      "Train Loss: 0.713951587677002\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 74.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2000 iterations: 6.661552727222443 mins\n",
      "Train Loss: 0.6450153589248657\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 66.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2200 iterations: 7.315540456771851 mins\n",
      "Train Loss: 0.7610032558441162\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 79.0% 10 way one-shot learning accuracy \n",
      "\n",
      "Current best: 79.0, previous best: 78.0\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2400 iterations: 7.967620933055878 mins\n",
      "Train Loss: 0.4899356961250305\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 79.0% 10 way one-shot learning accuracy \n",
      "\n",
      "Current best: 79.0, previous best: 79.0\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2600 iterations: 8.61935751438141 mins\n",
      "Train Loss: 0.6920003890991211\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 73.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 2800 iterations: 9.271013565858205 mins\n",
      "Train Loss: 0.45780009031295776\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 76.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3000 iterations: 9.922832119464875 mins\n",
      "Train Loss: 0.4898974895477295\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 77.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3200 iterations: 10.575814576943715 mins\n",
      "Train Loss: 0.4713599979877472\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 82.0% 10 way one-shot learning accuracy \n",
      "\n",
      "Current best: 82.0, previous best: 79.0\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3400 iterations: 11.227372380097707 mins\n",
      "Train Loss: 0.48842087388038635\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 73.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3600 iterations: 11.8801504611969 mins\n",
      "Train Loss: 0.4822166860103607\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 80.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 3800 iterations: 12.53288020292918 mins\n",
      "Train Loss: 0.48823583126068115\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 79.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4000 iterations: 13.18738021850586 mins\n",
      "Train Loss: 0.5567492246627808\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 79.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4200 iterations: 13.839160207907359 mins\n",
      "Train Loss: 0.38387560844421387\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 87.0% 10 way one-shot learning accuracy \n",
      "\n",
      "Current best: 87.0, previous best: 82.0\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4400 iterations: 14.492668072382608 mins\n",
      "Train Loss: 0.38604605197906494\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 83.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4600 iterations: 15.145740346113842 mins\n",
      "Train Loss: 0.2802683115005493\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 80.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 4800 iterations: 15.799223216374715 mins\n",
      "Train Loss: 0.3903367221355438\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 79.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5000 iterations: 16.45431152979533 mins\n",
      "Train Loss: 0.42384564876556396\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 76.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5200 iterations: 17.116062033176423 mins\n",
      "Train Loss: 0.43909239768981934\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 84.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5400 iterations: 17.76987871726354 mins\n",
      "Train Loss: 0.372358500957489\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 89.0% 10 way one-shot learning accuracy \n",
      "\n",
      "Current best: 89.0, previous best: 87.0\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5600 iterations: 18.42566374142965 mins\n",
      "Train Loss: 0.3227046728134155\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 86.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 5800 iterations: 19.081277612845103 mins\n",
      "Train Loss: 0.2884233593940735\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 82.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6000 iterations: 19.73468883037567 mins\n",
      "Train Loss: 0.3274652361869812\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 80.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6200 iterations: 20.390055553118387 mins\n",
      "Train Loss: 0.22677010297775269\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 83.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6400 iterations: 21.044155379136402 mins\n",
      "Train Loss: 0.26681023836135864\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 89.0% 10 way one-shot learning accuracy \n",
      "\n",
      "Current best: 89.0, previous best: 89.0\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6600 iterations: 21.697547841072083 mins\n",
      "Train Loss: 0.37830865383148193\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 84.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 6800 iterations: 22.351510898272196 mins\n",
      "Train Loss: 0.2556779980659485\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 80.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7000 iterations: 23.007345457871754 mins\n",
      "Train Loss: 0.3858852982521057\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 84.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7200 iterations: 23.661903591950736 mins\n",
      "Train Loss: 0.2356073558330536\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 78.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7400 iterations: 24.31603559652964 mins\n",
      "Train Loss: 0.36235523223876953\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 79.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7600 iterations: 24.970931001504262 mins\n",
      "Train Loss: 0.2678070366382599\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 84.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 7800 iterations: 25.62310910622279 mins\n",
      "Train Loss: 0.26011964678764343\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 83.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8000 iterations: 26.275397674242654 mins\n",
      "Train Loss: 0.22901859879493713\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 80.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8200 iterations: 26.928560451666513 mins\n",
      "Train Loss: 0.2551763653755188\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 84.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8400 iterations: 27.580617610613505 mins\n",
      "Train Loss: 0.26719313859939575\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 88.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8600 iterations: 28.23207907676697 mins\n",
      "Train Loss: 0.3576381504535675\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 84.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 8800 iterations: 28.884316925207774 mins\n",
      "Train Loss: 0.2093120664358139\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 87.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9000 iterations: 29.538198204835258 mins\n",
      "Train Loss: 0.19856370985507965\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 79.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9200 iterations: 30.18927193482717 mins\n",
      "Train Loss: 0.20132260024547577\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 83.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9400 iterations: 30.840833779176076 mins\n",
      "Train Loss: 0.20473292469978333\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 90.0% 10 way one-shot learning accuracy \n",
      "\n",
      "Current best: 90.0, previous best: 89.0\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9600 iterations: 31.491251718997955 mins\n",
      "Train Loss: 0.2765466570854187\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 86.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 9800 iterations: 32.14127281109492 mins\n",
      "Train Loss: 0.24820467829704285\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 84.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10000 iterations: 32.7912872672081 mins\n",
      "Train Loss: 0.35392072796821594\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 87.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10200 iterations: 33.44071949323018 mins\n",
      "Train Loss: 0.20768225193023682\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 89.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10400 iterations: 34.09016750653585 mins\n",
      "Train Loss: 0.27117133140563965\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 89.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10600 iterations: 34.74026654561361 mins\n",
      "Train Loss: 0.30834564566612244\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 89.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 10800 iterations: 35.38951519727707 mins\n",
      "Train Loss: 0.4196649193763733\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 88.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11000 iterations: 36.03889538049698 mins\n",
      "Train Loss: 0.32293054461479187\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 83.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11200 iterations: 36.68855089346568 mins\n",
      "Train Loss: 0.200373113155365\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 87.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11400 iterations: 37.336628611882524 mins\n",
      "Train Loss: 0.5324183106422424\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 88.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11600 iterations: 37.98482987483342 mins\n",
      "Train Loss: 0.16283324360847473\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 86.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 11800 iterations: 38.63294018507004 mins\n",
      "Train Loss: 0.25280988216400146\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 86.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12000 iterations: 39.27941627105077 mins\n",
      "Train Loss: 0.2946619987487793\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 90.0% 10 way one-shot learning accuracy \n",
      "\n",
      "Current best: 90.0, previous best: 90.0\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12200 iterations: 39.928233782450356 mins\n",
      "Train Loss: 0.2027411013841629\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 90.0% 10 way one-shot learning accuracy \n",
      "\n",
      "Current best: 90.0, previous best: 90.0\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12400 iterations: 40.576182019710544 mins\n",
      "Train Loss: 0.258769154548645\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 86.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12600 iterations: 41.22404410441717 mins\n",
      "Train Loss: 0.17990490794181824\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 82.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 12800 iterations: 41.87244469722112 mins\n",
      "Train Loss: 0.22036029398441315\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 92.0% 10 way one-shot learning accuracy \n",
      "\n",
      "Current best: 92.0, previous best: 90.0\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13000 iterations: 42.52072098255157 mins\n",
      "Train Loss: 0.17834711074829102\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 80.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13200 iterations: 43.170109283924106 mins\n",
      "Train Loss: 0.18212437629699707\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 91.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13400 iterations: 43.81757824023565 mins\n",
      "Train Loss: 0.1995730996131897\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 90.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13600 iterations: 44.466184349854785 mins\n",
      "Train Loss: 0.1733701229095459\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 89.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 13800 iterations: 45.11312888463338 mins\n",
      "Train Loss: 0.18915073573589325\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 83.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14000 iterations: 45.759339622656505 mins\n",
      "Train Loss: 0.1683434247970581\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 84.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14200 iterations: 46.40652443965276 mins\n",
      "Train Loss: 0.15311002731323242\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 84.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14400 iterations: 47.05421660343806 mins\n",
      "Train Loss: 0.16971856355667114\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 86.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14600 iterations: 47.70308572053909 mins\n",
      "Train Loss: 0.22729195654392242\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 91.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 14800 iterations: 48.35174281199773 mins\n",
      "Train Loss: 0.3465595543384552\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 89.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15000 iterations: 49.00177976687749 mins\n",
      "Train Loss: 0.20503810048103333\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 90.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15200 iterations: 49.649639038244885 mins\n",
      "Train Loss: 0.1693955957889557\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 87.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15400 iterations: 50.297736287117004 mins\n",
      "Train Loss: 0.24421733617782593\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 85.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15600 iterations: 50.945607952276866 mins\n",
      "Train Loss: 0.18056827783584595\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 94.0% 10 way one-shot learning accuracy \n",
      "\n",
      "Current best: 94.0, previous best: 92.0\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 15800 iterations: 51.5931898911794 mins\n",
      "Train Loss: 0.16198056936264038\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 82.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16000 iterations: 52.2419793844223 mins\n",
      "Train Loss: 0.15851916372776031\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 86.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16200 iterations: 52.890455134709676 mins\n",
      "Train Loss: 0.20650401711463928\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 95.0% 10 way one-shot learning accuracy \n",
      "\n",
      "Current best: 95.0, previous best: 94.0\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16400 iterations: 53.539031624794006 mins\n",
      "Train Loss: 0.20524254441261292\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 87.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16600 iterations: 54.187650167942046 mins\n",
      "Train Loss: 0.15972371399402618\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 84.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 16800 iterations: 54.835634160041806 mins\n",
      "Train Loss: 0.174307182431221\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 87.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17000 iterations: 55.48534028132757 mins\n",
      "Train Loss: 0.24924319982528687\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 86.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17200 iterations: 56.13533837397893 mins\n",
      "Train Loss: 0.3054618835449219\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 90.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17400 iterations: 56.783942969640094 mins\n",
      "Train Loss: 0.1958850920200348\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 90.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17600 iterations: 57.432058032353716 mins\n",
      "Train Loss: 0.15200857818126678\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 82.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 17800 iterations: 58.08020183642705 mins\n",
      "Train Loss: 0.15858256816864014\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 87.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18000 iterations: 58.727105577786766 mins\n",
      "Train Loss: 0.14163057506084442\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 89.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18200 iterations: 59.374513232707976 mins\n",
      "Train Loss: 0.1849285066127777\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 93.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18400 iterations: 60.02258191903432 mins\n",
      "Train Loss: 0.1470552682876587\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 88.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18600 iterations: 60.66981041431427 mins\n",
      "Train Loss: 0.1938284933567047\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 91.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 18800 iterations: 61.31671669483185 mins\n",
      "Train Loss: 0.16633598506450653\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 82.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19000 iterations: 61.966355729103086 mins\n",
      "Train Loss: 0.14250853657722473\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 89.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19200 iterations: 62.6151025334994 mins\n",
      "Train Loss: 0.14572694897651672\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 95.0% 10 way one-shot learning accuracy \n",
      "\n",
      "Current best: 95.0, previous best: 95.0\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19400 iterations: 63.265007400512694 mins\n",
      "Train Loss: 0.13666275143623352\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 80.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19600 iterations: 63.91288855075836 mins\n",
      "Train Loss: 0.15866215527057648\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 92.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 19800 iterations: 64.56136749188106 mins\n",
      "Train Loss: 0.22137370705604553\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 92.0% 10 way one-shot learning accuracy \n",
      "\n",
      "\n",
      " ------------- \n",
      "\n",
      "Time for 20000 iterations: 65.20981880426407 mins\n",
      "Train Loss: 0.20291785895824432\n",
      "Evaluating model on 100 random 10 way one-shot learning tasks ... \n",
      "\n",
      "Got an average of 89.0% 10 way one-shot learning accuracy \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training process!\")\n",
    "print(\"-------------------------------------\")\n",
    "t_start = time.time()\n",
    "for i in range(1, n_iter+1):\n",
    "    (inputs,targets) = get_batch(batch_size)\n",
    "    loss = model.train_on_batch(inputs, targets)\n",
    "    if i % evaluate_every == 0:\n",
    "        print(\"\\n ------------- \\n\")\n",
    "        print(\"Time for {0} iterations: {1} mins\".format(i, (time.time()-t_start)/60.0))\n",
    "        print(\"Train Loss: {0}\".format(loss)) \n",
    "        val_acc = test_oneshot(model, N_way, n_val, verbose=True)\n",
    "        model.save_weights(os.path.join(model_path, 'weights.{}.h5'.format(i)))\n",
    "        if val_acc >= best:\n",
    "            print(\"Current best: {0}, previous best: {1}\".format(val_acc, best))\n",
    "            best = val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "CGuRFhXk4nAq",
    "outputId": "559b3930-2508-48c5-a372-51d4dd39953d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2, 10, 105, 105, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.load('test.npy')\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sAJLs9LJ4nBX"
   },
   "source": [
    "## Predicting for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wFvSN4Q-4nBY"
   },
   "outputs": [],
   "source": [
    "# Choose weights with best accuracy\n",
    "model.load_weights(os.path.join(model_path, \"weights.19200.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3362
    },
    "colab_type": "code",
    "id": "eiwRQWsmDqT7",
    "outputId": "d130a7dc-d1d0-4c7c-9698-544caadc597f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 9,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 5,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 7,\n",
       " 4]"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "for test_sample in in range(test_data):\n",
    "    probabilities = model.predict([test_sample[0], test_sample[1]])\n",
    "    predictions.append(np.argmax(probabilities))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oSxhkzV6DqbP"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "output_dict = OrderedDict()\n",
    "output_dict['Id'] = list(range(len(test_data)))\n",
    "output_dict['Category'] = predictions\n",
    "output_df = pd.DataFrame(data = output_dict)\n",
    "output_df.to_csv(\"output.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "6I3qYKAX4nBe",
    "ymMtjkTB4nBg",
    "BgSLVoqy4nCo",
    "TtizDLzY4nCu",
    "JbRSbYPU4nC0",
    "-dQtuO_m4nD0"
   ],
   "name": "Siamese on Omniglot Dataset.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
